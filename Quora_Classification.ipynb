{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e4239e-04b9-47d8-950a-361ca69a0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "pd.set_option('max_colwidth',400)\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"F-score is ill-defined and being set to 0.0 due to no predicted samples.\")\n",
    "import re\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f074e932-b557-4ba3-8ecf-65fc224a04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed = 1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8fc408b-87c8-4769-ba2b-ed34f5fe759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "val = pd.read_csv(\"test.csv\")\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25d0e73-2d6e-48fb-91c1-c2b6e94bdf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "\n",
    "def space_punkt(x):\n",
    "    \"\"\"Добавляет пробелы до и после знаков пунктуации — это необходимо для дальнейшей токенизации\"\"\"\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "                \"can't\" : \"cannot\",\n",
    "                \"couldn't\" : \"could not\",\n",
    "                \"didn't\" : \"did not\",\n",
    "                \"doesn't\" : \"does not\",\n",
    "                \"don't\" : \"do not\",\n",
    "                \"hadn't\" : \"had not\",\n",
    "                \"hasn't\" : \"has not\",\n",
    "                \"haven't\" : \"have not\",\n",
    "                \"he'd\" : \"he would\",\n",
    "                \"he'll\" : \"he will\",\n",
    "                \"he's\" : \"he is\",\n",
    "                \"i'd\" : \"I would\",\n",
    "                \"i'll\" : \"I will\",\n",
    "                \"i'm\" : \"I am\",\n",
    "                \"isn't\" : \"is not\",\n",
    "                \"it's\" : \"it is\",\n",
    "                \"it'll\":\"it will\",\n",
    "                \"i've\" : \"I have\",\n",
    "                \"let's\" : \"let us\",\n",
    "                \"mightn't\" : \"might not\",\n",
    "                \"mustn't\" : \"must not\",\n",
    "                \"shan't\" : \"shall not\",\n",
    "                \"she'd\" : \"she would\",\n",
    "                \"she'll\" : \"she will\",\n",
    "                \"she's\" : \"she is\",\n",
    "                \"shouldn't\" : \"should not\",\n",
    "                \"that's\" : \"that is\",\n",
    "                \"there's\" : \"there is\",\n",
    "                \"they'd\" : \"they would\",\n",
    "                \"they'll\" : \"they will\",\n",
    "                \"they're\" : \"they are\",\n",
    "                \"they've\" : \"they have\",\n",
    "                \"we'd\" : \"we would\",\n",
    "                \"we're\" : \"we are\",\n",
    "                \"weren't\" : \"were not\",\n",
    "                \"we've\" : \"we have\",\n",
    "                \"what'll\" : \"what will\",\n",
    "                \"what're\" : \"what are\",\n",
    "                \"what's\" : \"what is\",\n",
    "                \"what've\" : \"what have\",\n",
    "                \"where's\" : \"where is\",\n",
    "                \"who'd\" : \"who would\",\n",
    "                \"who'll\" : \"who will\",\n",
    "                \"who're\" : \"who are\",\n",
    "                \"who's\" : \"who is\",\n",
    "                \"who've\" : \"who have\",\n",
    "                \"won't\" : \"will not\",\n",
    "                \"wouldn't\" : \"would not\",\n",
    "                \"you'd\" : \"you would\",\n",
    "                \"you'll\" : \"you will\",\n",
    "                \"you're\" : \"you are\",\n",
    "                \"you've\" : \"you have\",\n",
    "                \"'re\": \" are\",\n",
    "                \"wasn't\": \"was not\",\n",
    "                \"we'll\":\" will\",\n",
    "                \"didn't\": \"did not\",\n",
    "                \"tryin'\":\"trying\"}\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: space_punkt(x.lower()))\n",
    "val[\"question_text\"] = val[\"question_text\"].apply(lambda x: space_punkt(x.lower()))\n",
    "\n",
    "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
    "val[\"question_text\"] = val[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
    "\n",
    "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n",
    "val[\"question_text\"] = val[\"question_text\"].apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ed6099-0239-4e7d-acbb-11421af8a793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGzCAYAAAAmH71NAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOvdJREFUeJzt3Ql8VNXZ+PEnISSISASiCQFCXHAJq4aAKC5IFAFRqVrXGtDSqnGpuDRp/5palaDUFJFq6hIita8ircYFcYsgLmhYDIhUJBI0RSEgGjZJILn/z3N8Z96ZycKQTDKTM7/v53M1987lzpm7Pvec59wb4TiOIwAAABaKDHYBAAAAWguBDgAAsBaBDgAAsBaBDgAAsBaBDgAAsBaBDgAAsBaBDgAAsBaBDgAAsBaBDgAAsBaBTpj505/+JBEREW3yXWeddZYZXBYvXmy++1//+lebfP+kSZMkOTlZQtmuXbvk17/+tSQkJJh187vf/U5sU1hYaH7bxo0bg12UkOF7bIT6+WLbtm3t5hhs6/MMQh+BjgUXENfQqVMnSUxMlDFjxsisWbNk586dAfmeb7/91pzwSktLJdSEctn8MW3aNLMdb7jhBvnHP/4hv/rVr6S90t9SVFQk4Vim119/3eyH7VUobrtw9NFHH5n96Mcffwx2Ueyi77pC+zRnzhx9T5nz5z//2fnHP/7hFBQUONOmTXPOPfdcJyIiwunbt6+zatUqr3+zb98+56effjqo71m2bJn5Hv2+g1FdXW0Gl0WLFpnlzJ8//6CW09yy1dTUOHv37nVC2fDhw53TTjvNscGhhx7qZGRk1Ju+f/9+s8/V1dWFTJkCLTMz0+yH/jrzzDPNECoaW085OTnmd23durVZyw3GMdga55m2MmPGDFP28vLyYBfFKlHBDrTQcmPHjpWhQ4e6x7Ozs+Xdd9+V888/Xy644AL5z3/+I4cccoj5LCoqygytac+ePdK5c2eJjo6WYOrYsaOEusrKSklJSRGbdejQwQwIP+3hGGyu3bt3y6GHHirtwZ7/PSeHK5quLHX22WfL3XffLV9//bU8++yzTebovP322zJy5Eg5/PDDpUuXLnL88cfLH/7wB3d7d1pamvl78uTJ7mYybW5RmmcwYMAAWbFihZxxxhnmYHL928byEGpra808mpeiJwoNxioqKrzm0XZ9bd/35bnMA5WtofwAPTndfvvt0qdPH4mJiTG/9S9/+YveinvNp8u56aabTHW+/j6dt3///vLGG2/4HcBcd911Eh8fb5oUBw8eLM8880y9PILy8nJZsGCBu+xN5bFUV1fLbbfdJkcccYQcdthhZr3997//Nf/Os9mksbyIxvKzdP9ITU01wXD37t3l8ssvr7c91q9fLxdffLHZZvp7evfubearqqpyry9dt/obXb/Ftf0ay9F57LHHzDrVdatNrpmZmfWq7F3719q1a2XUqFFm/+rVq5c89NBDB9wGTZVJbdq0Sa699lqzjVzbt6CgwP35Tz/9JCeccIIZ9G+X7du3S8+ePeXUU081+7Iu829/+5v7O13DwdLtm5OTI8cee6wpj+6jd911l5ne3H1T9zO9CdJtdswxx8jf//73evvBgdaT0u2i0/QcERsba443vXgeiO++qPuALl+PuSeeeMKUScuvx/GyZcv8Wk9aFj0OdLn6b3VfvOaaa+rlEdXV1ckDDzxgPtffP3r0aCkrK/Oa5/3335dLL71UkpKS3Otcl+25vV2/Q8+NX331lYwbN84cf1ddddVBLUN98cUX8stf/tIcw3q86fnnj3/8o/lMt8udd95p/j7qqKMaPCf4c6w2dU5evny5SW2Ii4szy9Dv0WPAdtToWEzzPXQHf+utt2TKlCkNzvP555+bmp9BgwbJn//8Z3Og6sngww8/NJ+feOKJZvo999wjv/nNb+T000830/Uk7/L999+bWiU96K6++mpz4WiKnnz0AP79739vAoKZM2dKenq6ybNx1Tz5w5+yedJgRoODRYsWmSBkyJAh8uabb5qTi170/vrXv3rN/8EHH8iLL74oN954ozmxad6TXuy/+eYb6dGjR6Pl0hOcnmx0PeoFSU8m8+fPNydLPUnfeuutpuyak6MnRD0Ra/Cl9ATYGE1a1hPdlVdeaX6j1tqNHz9eWkK3hQbEevLV5W/dulUeffRRc4L89NNPzYWtpqbGnBz1gnvzzTebYEfX12uvvWZ+j1749Lfovx82bJjZFkovYo3Rk/q9995rtrvmJ61bt04ef/xxc7HTfc+zJuCHH36Q8847T37xi1+YcmqSqe47AwcONPtdY5oq05YtW+SUU05xBw263hcuXGj2ix07dpikcN0X9eJ/2mmnmYtRXl6e+bcakGmApwGc1lT99re/NbliesOg39kcelHWfVP3OS2r7h+fffaZ2Se//PLLevkz/uybuv10vWlQputagzI9Xnz3MX+2na533Y9zc3Nl5cqV8tRTT8mRRx4pDz74YLN+7//8z/+YHEJdd7oNNHDV7bthw4Yma4E0eV+Pc62l1gv0ySefbAKcV155xQT9egF3mT59ukRGRsodd9xhtpd+hwYnn3zyiXsePS41YNN9UNdbSUmJ2f91WfqZp/3795vjQG8KNVBz1ZD4u4zVq1ebsuvv0/WsgZoGTq+++qo5DvX367Z+7rnnzHZ3/RbX9vLnWG3qnFxZWSnnnnuuWV5WVpaZX4Mo3Y+sF+y2M7Q8R0fzVBoTGxvrnHTSSfXa3F3++te/HrANvqk8GM0z0M/y8/MPmIfgajvv1auXs2PHDvf0F154wUx/5JFH3NM0v6ihnAHfZTZVNv33uhyXoqIiM+/999/vNd8ll1xicprKysrc03S+6Ohor2ma76TTH330UacpM2fONPM9++yzXrkKI0aMcLp06eL127V848ePdw6ktLTULPPGG2/0mn7llVea6bpdG/vdjW37jRs3Oh06dHAeeOABr/k+++wzJyoqyj39008/9SvnobE8D9d+6so7qKysNOtWc8lqa2vd882ePdvMp7lmvvvX3Llz3dM07yshIcG5+OKLmyxPU2W67rrrnJ49ezrbtm3zmn755ZebY2bPnj3uadnZ2U5kZKSzZMkSsw60PLqNA5mjozl2+h3vv/++13x6XOlyP/zww4PeNydMmOB07tzZ2bRpk3va+vXrzbb1LeuBcnSuvfZar+kTJ050evToccDf6bsv6j6gy9N/u337dvf0l19+2Ux/9dVXm1zePffcY+Z78cUX633mygFznWdOPPFErxxBPb/odN2/XTy3s0tubq45H3z99ddev0P/bVZWVr35/V3GGWec4Rx22GFe0zzL3VSOjr/HalPn5JdeeumA1wtb0XRlOa1ubar3lesu4OWXXzZ3lc2htUBale0vrWbWu1CXSy65xNx1as+V1qTL1zvwW265xWu61qbo9UPv6D1pbYPnna3WenXt2tXcdR7oe7TW44orrnBP07s4/V69I33vvfeaVXblW/aWdEfXOznd5nqHqHfFrkHL3q9fP1PzpbTGRmntlz/NFQfyzjvvmFoiLbvecbtoraOuX23K892H9a7URXO/tPbhQNuhMbqt//3vf8uECRPM356/Xe/Y9e5fay08a5+0aSgjI8PUoJx55pn1tkNL6Z2/1uJoM5lnebQJWrm2hb/7ptbe6Hq+6KKLTLOgizaLNVUL1pjrr7/ea1xrJrTWQGu/muOyyy6Tbt26eS1PHWib6nbTZuCJEyfW+8y3uVDPSZ55gg19h2cNsjbf6TrX2lLdL7SWxJfW2vjyZxla+7JkyRJTC6VNXE2VuyXHalPn5MP/91yvNbH79u2TcEKgYzm9sHoGFQ2dcLRqXqtCtXpTqzpfeOGFgwp6NGfiYBKP9cD0PdD1BNzaz1nRfCU96fuuD73AuD735HtCUnpy1qaUA32P/kbPi3hT3+Nv2XV5vk0K2sbfXJp3oydjLatWZ3sO2jSgVd1KmyymTp1qmiu0Ol2DAc1JceXnNOe3NFR23YeOPvroeutHm/Z8Lwb+bIfG6EVHm9w0R8T3d7suDq7f7iqX5u5oPpXeNMyZMyfgz6LSbaHNyL7lOe644+qVx599U+fXJlQ9rnw1NO1AfL/PFaQ0dxs0d3na1KP5J4H6Dm3q0yZlzXfRgFrXuQayynf/1k4cui/68mcZruDK37I391ht6px85plnmuZNbcbU4/jCCy80+7JvDpiNyNGxmLYR64HW1IlN70b0TkPvCPROWhMa582bZ+4kNbfHn94yB5NX46/GLiR6p9pWPXga+x7fxOVQ09S686TBrM6rNVkN/VY9abs8/PDD5mSuNX+6X2iNhuZrfPzxxw2e/EN5O7iCeK0l0lqahmgNiSetzVJ79+41Fx0N/gJJy6Q5R648IF+a4BrMfTPQ39cW5T/Qd+jxcM4555jkcs350to07Ryh+We6r/ve7Gktie/Ny8Euo7kO5lht7Jwc8b8PUdRjVvOCdJ/WGiY9tnWa7zJsQqBjMVdipN6BN0UPXu2RoIOeaPXhYZp8qcGPVpG3xt2r74lHE3c9Ly5699XQQ7P0bl/v+l0Opmx9+/Y11fl6V+5Zq6M9IVyfB4IuRxMP9eTkeWJsyffov9Hl6R2tZ02IJvH6amrdedLaIV33etF21Rw0RS/EOvy///f/zIPNtCYwPz9f7r///oPaFq7fr2X33JbanKW1JrrPBUpDZXL1WtOLlD/fpdtSk3i1tkcT5rX2UxOFXU16jX3PwdBtsWrVKnMMBuJ400Rh7Wnk28tINTStrZ6W3lK6ntasWROQZek21ORfTTjX5nQXTSoP9DJc+/mByt7YdjjYY7Upp5xyihk0uVmTwjVB+/nnnzf7ta1ourKU9si57777zIHh6gbZEL0T8aW9kZSrStP1rIhAPa1z7ty5XnlDepfx3XffeeUO6IGtdxl68XPRtmXfrpQHUzbtFqoXt9mzZ3tN1x4OeoJpTu5CY9+zefNmUzPm2WNDe0joXZOrWvtguMqmvWs8aY81X7rutCZPL9Auun5feuklr/m0l4feHWpVtu+dtI5rDobSPAwtvycNeDSI86z21m3hz3bQ4EKr1fW3eH7v008/bcrd0p5knhoqk/5mrcLXfI+GLjzatOWiuQx6Z65Nno888ojpaaU9trS3nO/3tOQY0dwLrQV48skn632mTVCa+3Ew9DfqetbeWtojzDPI8c1Fc5W/PTyNV7ebBoS++3JzaoNcNSOe/07/1u0c6GVocK29o7QJVJu6Git3Y/uRv8dqU3744Yd6/9b3XG8ranQsoCcurS3Qi5GehDXI0TsKvXPWbpd6Z9cYvVPVpiu9uOj82tarzzfR5gjtRum6cGoim969652wHozDhw9vdvW9tmXrsvUOWcurF2ttXvPsAq93FxoAafdYvQhoTYZ2rfbNUTmYsmnyqT6LRWurNB9Ikxq1GUabYzQxtqnu0AdDu47q80r0AqnPstBupPpbtNu0/tamcqYaoyckTW7WbaPBgCY7FhcXN3h3rnlWWo2uCZvaxKQJxNp1W+8EPZNs9fdqbYw+YFLXhyauatm0VkUvJPo7tGuu7k/aBVufFaLL0P1MawtdAYOLPt9Da8y0VlADA90Gui186Ulfv1NP2rp9tVu11u7ob9PnqXgmHrdUY2XSrsdaY6l/636nD23UoF/Xj87vugHQ9aO1OLqudd1oraM+zkBrtTSJXoNa1/coXd9ag6rrRrfDwTwKQnPjNOlXy6W1ZRqU63Gt07WZwfOhoP7QJGrdv3VZmkTrCvI1T8T3lSn+brtg00dB6LGk+6I2u2i5dVvpeU7PAXpM+0ubmfQY0H1cg0xN5tbg92Dyjg5mGRrY63lPu8TrsaXrWI87TRlwbQ/XfqTnKN1/tBODnrf8PVab8swzz5hjTM8Lujy92dTAWsvs2o+tFexuX2g+V7dd16BdTrXb7TnnnGO6Unp2Y26si3FxcbFz4YUXOomJiebf6/+vuOIK58svv/T6d9r9MyUlxd011dWdW7sy9u/fv8HyNda9/LnnnjNddo888kjnkEMOMd2rfbtcqocffth0RY+JiTGvSVi+fHmDj85vrGwNdbPeuXOnc9ttt5nf2bFjR6dfv36mS6fv6wl0Odpl2Fdj3d59bdmyxZk8ebITFxdn1uvAgQMb7ALvb/dypa9RuOWWW0zXXO0OrN2HKyoq6nUvV2+99ZYzYMAA893HH3+86eruu+1d/v3vfzsjR440y9ThhBNOML993bp15vMNGzaY7sXHHHOM06lTJ6d79+7OqFGjnHfeecdrOV988YXpQqvbVL/HtZ58u5d7difX79LtEB8f79xwww3ODz/84DVPY/tXY13ofTVWJtc20t/Zp08fUwY9dkaPHu088cQT5vMVK1aYfermm2+u90qLtLQ0sw+5yqvTdL4jjjjCdCs+0Km1of1YH0Hw4IMPmt+r+3y3bt2c1NRU595773WqqqqatW/q8a2Pl9D9QLffU0895dx+++1mO/qznhp7BURj29Tf7uV6zPlqaD9uyPfff+/cdNNN5tygv6t3797me1yPCmjsFRCu7/Y8DteuXeukp6ebxz7osTplyhR3V33P+XT5emw0xN9lqDVr1piu+YcffrjZBnps3n333V7z3Hfffea36eMGfNfxgY7Vpo6ZlStXmnN7UlKS2b/0/Hv++eeb86rtIvQ/wQ62ADSfNrvpE3Xb80sl0Xa0NkB7ePnmygG2IkcHACzl+xoCDW70mUwNvZoFsBU5OgBgKe3to7lirucTaa6WJoLrO7SAcEGgAwCW0mRvfXeS9gLU58CMGDHCPD7C96GdgM3I0QEAANYiRwcAAFiLQAcAAFgr7HN09LH6+uRQffhSe3kMOgAA4c5xHPPgQ33Ipe97yDyFfaCjQY7vC/MAAED7oK8GaurlwmEf6Lgex68rSh+FDQAAQp++h08rKg70Wp2wD3RczVUa5BDoAADQvhwo7YRkZAAAYC0CHQAAYC0CHQAAYK2wDXT+9re/SUpKiqSlpQW7KAAAoJWE/SsgNGs7NjZWqqqqSEYGAMCy63fY1ugAAAD7EegAAABrEegAAABrEegAAABrEegAAABrEegAAABrEegAAABrEegAAABrhf3by1tTctYCaW82Th8f7CIAABAwVtTolJeXy6hRo8wrHQYOHCi7d+8OdpEAAEAIsKJGZ9KkSXL//ffL6aefLtu3b5eYmJhgFwkAAISAdh/ofP7559KxY0cT5Kju3bsHu0gAACBEBL3pasmSJTJhwgRJTEyUiIgIKSoqavBN48nJydKpUycZPny4lJSUuD9bv369dOnSxSzj5JNPlmnTprXxLwAAAKEq6IGO5tMMHjzYBDMNmTdvnkydOlVycnJk5cqVZt4xY8ZIZWWl+Xz//v3y/vvvy2OPPSZLly6Vt99+2wwAAABBD3TGjh1r8msmTpzY4Od5eXkyZcoUmTx5skk2zs/Pl86dO0tBQYH5vFevXjJ06FDp06ePyc0ZN26clJaWNvp91dXV5tXungMAALBT0AOdptTU1MiKFSskPT3dPS0yMtKMa+2NSktLM7U7P/zwg9TV1ZmmsBNPPLHRZebm5kpsbKx70AAJAADYKaQDnW3btkltba3Ex8d7TdfxzZs3m7+joqJMXs4ZZ5whgwYNkn79+sn555/f6DKzs7OlqqrKPVRUVLT67wAAAMHR7ntduZq/dPCHNm/poDlBOmggBQAA7BTSNTpxcXHSoUMH2bJli9d0HU9ISGjRsjMzM2Xt2rWybNmyFpYSAACEqpAOdKKjoyU1NVWKi4vd0zQPR8dHjBgR1LIBAIDQF/Smq127dklZWZnX6xy015Q++C8pKcl0Lc/IyDA9q4YNGyYzZ840XdK1F1ZL0HQFAID9IhzHcYJZgMWLF5v3VPnS4KawsND8PXv2bJkxY4ZJQB4yZIjMmjXLPDgwELR7ufa+0sTkrl27SiDxUk8AAFqHv9fvoAc6wUag441ABwBg0/U7pHN0WpM2W+kDCPU5PAAAwE5hG+jQ6woAAPuFbaADAADsR6ADAACsFbaBDjk6AADYL2wDHXJ0AACwX9gGOgAAwH4EOgAAwFphG+iQowMAgP3CNtAhRwcAAPuFbaADAADsR6ADAACsRaADAACsRaADAACsFbaBDr2uAACwX9gGOvS6AgDAfmEb6AAAAPsR6AAAAGsR6AAAAGsR6AAAAGsR6AAAAGuFbaBD93IAAOwXtoEO3csBALBf2AY6AADAfgQ6AADAWgQ6AADAWgQ6AADAWgQ6AADAWgQ6AADAWgQ6AADAWmEb6PDAQAAA7Be2gQ4PDAQAwH5hG+gAAAD7EegAAABrEegAAABrEegAAABrEegAAABrEegAAABrEegAAABrEegAAABrEegAAABrRYkFkpOTpWvXrhIZGSndunWTRYsWBbtIAAAgBFgR6KiPPvpIunTpEuxiAACAEELTFQAAsFbQA50lS5bIhAkTJDExUSIiIqSoqKjBN41r81SnTp1k+PDhUlJS4vW5/rszzzzTvIn8n//8ZxuWHgAAhLKgBzq7d++WwYMHm2CmIfPmzZOpU6dKTk6OrFy50sw7ZswYqaysdM/zwQcfyIoVK+SVV16RadOmyerVq9vwFwAAgFAV9EBn7Nixcv/998vEiRMb/DwvL0+mTJkikydPlpSUFMnPz5fOnTtLQUGBe55evXqZ//fs2VPGjRtnAqLGVFdXy44dO7wGAABgp6AHOk2pqakxNTXp6enuadqzSseXLl3qrhHauXOn+XvXrl3y7rvvSv/+/RtdZm5ursTGxrqHPn36tMEvAQAAwRDSgc62bduktrZW4uPjvabr+ObNm83fW7ZskZEjR5omrVNOOUWuueYak6vTmOzsbKmqqnIPFRUVrf47AABAcLT77uVHH320rFq1yu/5Y2JizKA5QTpoIAUAAOwU0jU6cXFx0qFDB1Nr40nHExISWrTszMxMWbt2rSxbtqyFpQQAAKEqpAOd6OhoSU1NleLiYve0uro6Mz5ixIiglg0AAIS+oDddaQJxWVmZe7y8vFxKS0ule/fukpSUZLqWZ2RkyNChQ2XYsGEyc+ZMk4CsvbBagqYrAADsF+E4jhPMAixevFhGjRpVb7oGN4WFhebv2bNny4wZM0wC8pAhQ2TWrFnmwYGBoN3LtfeVJibr+7ICKTlrgbQ3G6ePD3YRAAAI2PU76IFOsBHoeCPQAQDYdP0O6Ryd1qTNVvoAwqa6ogMAgPYtbAMdel0BAGC/sA10AACA/Qh0AACAtcI20CFHBwAA+4VtoEOODgAA9gvbQAcAANiPQAcAAFgrbAMdcnQAALBf2AY65OgAAGC/sA10AACA/Qh0AACAtQh0AACAtQh0AACAtcI20KHXFQAA9gvbQIdeVwAA2C9sAx0AAGA/Ah0AAGAtAh0AAGAtAh0AAGAtAh0AAGCtsA106F4OAID9wjbQoXs5AAD2C9tABwAA2I9ABwAAWItABwAAWItABwAAWItABwAAWItABwAAWItABwAAWCtsAx0eGAgAgP3CNtDhgYEAANgvbAMdAABgPwIdAABgLQIdAABgLQIdAABgLQIdAABgLQIdAABgLQIdAABgLQIdAABgLQIdAABgLWsCnT179kjfvn3ljjvuCHZRAABAiLAm0HnggQfklFNOCXYxAABACLEi0Fm/fr188cUXMnbs2GAXBQAAhJCgBzpLliyRCRMmSGJiokREREhRUVGDbxpPTk6WTp06yfDhw6WkpMTrc22uys3NbcNSAwCA9iDogc7u3btl8ODBJphpyLx582Tq1KmSk5MjK1euNPOOGTNGKisrzecvv/yyHHfccWYAAADwFCVBps1NTTU55eXlyZQpU2Ty5MlmPD8/XxYsWCAFBQWSlZUlH3/8sTz//PMyf/582bVrl+zbt0+6du0q99xzT4PLq66uNoPLjh07WuFXAQCAUBD0Gp2m1NTUyIoVKyQ9Pd09LTIy0owvXbrUjGuTVUVFhWzcuFH+8pe/mKCosSDHNX9sbKx76NOnT5v8FgAA0PZCOtDZtm2b1NbWSnx8vNd0Hd+8eXOzlpmdnS1VVVXuQYMkAABgp6A3XQXSpEmTDjhPTEyMGTQnSAcNpAAAgJ1CukYnLi5OOnToIFu2bPGaruMJCQktWnZmZqasXbtWli1b1sJSAgCAUBXSgU50dLSkpqZKcXGxe1pdXZ0ZHzFiRFDLBgAAQl/Qm660p1RZWZl7vLy8XEpLS6V79+6SlJRkupZnZGTI0KFDZdiwYTJz5kzTJd3VC6u5aLoCAMB+EY7jOMEswOLFi2XUqFH1pmtwU1hYaP6ePXu2zJgxwyQgDxkyRGbNmmUeHBgI2r1ce19pYrJ2Sw+k5KwF0t5snD4+2EUAACBg1++gBzrBRqDjjUAHAGDT9Tukc3RakzZbpaSkSFpaWrCLAgAAWknYBjr0ugIAwH5hG+gAAAD7EegAAABrhW2gQ44OAAD2C9tAhxwdAADsF7aBDgAAsB+BDgAAsFbYBjrk6AAAYL+wDXTI0QEAwH5hG+gAAAD7NSvQ2bBhQ+BLAgAAEAqBzrHHHmveOP7ss8/K3r17A10mAACA4AU6K1eulEGDBsnUqVMlISFBfvvb30pJSUlgSgQAABDMQGfIkCHyyCOPyLfffisFBQXy3XffyciRI2XAgAGSl5cnW7dulVBHrysAAOwX4TiO09KFVFdXy2OPPSbZ2dlSU1Mj0dHR8stf/lIefPBB6dmzp4SyHTt2SGxsrFRVVUnXrl0DuuzkrAXS3mycPj7YRQAAIGDX7xb1ulq+fLnceOONJpjRmpw77rhDvvrqK3n77bdNbc+FF17YksUDAAC0SFRz/pEGNXPmzJF169bJuHHjZO7cueb/kZE/x01HHXWUFBYWSnJycstKBwAA0NaBzuOPPy7XXnutTJo0qdGmqSOPPFKefvrplpQNAACg7QOd9evXH3AezdPJyMhozuIBAAAColk5OtpsNX/+/HrTddozzzwj7QG9rgAAsF+zAp3c3FyJi4trsLlq2rRp0h7wrisAAOzXrEDnm2++MQnHvvr27Ws+AwAAaLeBjtbcrF69ut70VatWSY8ePQJRLgAAgOAEOldccYXccsstsmjRIqmtrTXDu+++K7feeqtcfvnlLS8VAABAsHpd3XfffbJx40YZPXq0REX9vIi6ujq55ppr2k2ODgAAsF+zAh3tOj5v3jwT8Ghz1SGHHCIDBw40OToAAADtOtBxOe6448wAAABgTaCjOTn6iofi4mKprKw0zVaeNF8HAACgXQY6mnSsgc748eNlwIABEhEREfiSAQAABCPQef755+WFF14wL/Jsr/TJyDpo7RQAALBTZHOTkY899lhpz3gyMgAA9mtWoHP77bfLI488Io7jBL5EAAAAwWy6+uCDD8zDAhcuXCj9+/eXjh07en3+4osvBqp8AAAAbRvoHH744TJx4sTmfysAAECoBjpz5swJfEkAAABCIUdH7d+/X9555x35+9//Ljt37jTTvv32W9m1a1cgywcAANC2NTpff/21nHfeefLNN99IdXW1nHPOOXLYYYfJgw8+aMbz8/ObXyIAAIBg1ujoAwOHDh0qP/zwg3nPlYvm7ejTkgEAANptjc77778vH330kXmejqfk5GTZtGlToMoGAADQ9jU6+m6rhp4o/N///tc0YQEAALTbQOfcc8+VmTNnusf1XVeahJyTk9Pmr4X48ccfTTPakCFDzHu3nnzyyTb9fgAAYFnT1cMPPyxjxoyRlJQU2bt3r1x55ZWyfv16iYuLk+eee07aktYgLVmyRDp37iy7d+82wc4vfvEL6dGjR5uWAwAAWBLo9O7dW1atWmVe7rl69WpTm3PdddfJVVdd5ZWc3BY6dOhgghylPb70tRS8mgIAALToOTpRUVFy9dVXy0MPPSSPPfaY/PrXv25WkKO1MRMmTJDExETTBFZUVFRvHn3LuCY6d+rUSYYPHy4lJSX1mq8GDx5sArA777zT1CwBAAA0q0Zn7ty5TX5+zTXX+L0sbW7SIOXaa681TU6+5s2bJ1OnTjXP5tEgR3ODtNls3bp1cuSRR7pfSaE1TFu2bDHLuOSSSyQ+Pr4ZvwwAANgkwmlGO0+3bt28xvft2yd79uwx3c21GWn79u3NK0xEhLz00kty0UUXuadpcJOWliazZ8929/jq06eP3HzzzZKVlVVvGTfeeKOcffbZJthpiDZv6eCyY8cOs7yqqirp2rWrBFJy1gJpbzZOHx/sIgAAcEB6/Y6NjT3g9btZTVf6oEDPQXN0tIZl5MiRAU1GrqmpkRUrVkh6evr/FTgy0owvXbrUjGstjusVFPpjtSns+OOPb3SZubm5ZsW4Bg1yAACAnZqdo+OrX79+Mn36dPPU5EDZtm2beV6PbzOUjm/evNn9OorTTz/dNH/p/7WmZ+DAgY0uMzs72wRErqGioiJg5QUAABbk6DS6sKgo82LPtjRs2DApLS31e/6YmBgzaIKzDg09+BAAAIRxoPPKK694jWuaz3fffWfyaE477bRAlc30ntLu49o85UnHExISWrTszMxMM7ja+AAAgH2aFeh4Jgu7koiPOOIIkwSsDxMMFE1uTk1NNS8KdX2nJiPr+E033RSw7wEAAHZqVqCjwUagaCJzWVmZe7y8vNw0RXXv3l2SkpJM1/KMjAzzmgdtptLu5dolffLkyS36XpquAACwX7O6lwfS4sWLZdSoUfWma3BTWFho/tYmsRkzZpgEZH2n1axZs0y387bsntYcdC8HAKB1+Hv9blago7Us/srLy5NQRqDjjUAHANAe+Hv9blbT1aeffmoGfVCg65k1X375pUkcPvnkk71yd0IVTVcAANivWYGOvptK3xr+zDPPuJ+SrA8O1LwZfZbN7bffLqGOXlcAANivWQ8M1J5V+oRhz1dB6N/3339/QHtdAQAAtHmgo7UgW7durTddp7lexwAAANAum64mTpxomqm09ka7fKtPPvlE7rzzzgbfQB6KyNFpGAnUAACbNKvXlb6p/I477pCCggKTkOx6/cN1111nuoEfeuih0l7Q66r9I9ABgPCzozV7XXXu3Fkee+wxE9R89dVXZtoxxxzTrgIcAABgvxa9vVzfb6WDvrlcg5wgP3sQAACg5YHO999/L6NHj5bjjjtOxo0bZ4IdpU1X7aFrudL8nJSUFElLSwt2UQAAQCgFOrfddpt07NhRvvnmG9OM5XLZZZfJG2+8Ie2BPkNn7dq1smzZsmAXBQAAtJJm5ei89dZb8uabb0rv3r29pmsT1tdffx2osgEAALR9jY6+PdyzJsdl+/btEhMT07ISAQAABDPQ0dc8zJ071+udVnV1dfLQQw81+CZyAACAdtN0pQGNJiMvX75campq5K677pLPP//c1Oh8+OGHgS8lAABAW9XoDBgwwLytfOTIkXLhhReapix9IrK+0Vyfp9Me0OsKAAD7HfSTkfVJyOedd57k5+eb5OP2jicjt388GRkAws8OP6/fB12jo93KV69e3dLyAQAAhGbT1dVXXy1PP/104EsDAAAQ7GTk/fv3mxd6vvPOO5KamlrvHVd5eXmBKh8AAEDbBDobNmyQ5ORkWbNmjZx88slmmiYle9Ku5gAAAO0u0NHkY32v1aJFi9yvfJg1a5bEx8dLe6O9rnSora0NdlEAAEAo5Oj4dtBauHCh6VreHvGuKwAA7NesZGSXg+yZDgAAELqBjubf+ObgkJMDAACsyNHRGpxJkya5X9y5d+9euf766+v1unrxxRcDW0oAAIDWDnQyMjLqPU8HAADAikBnzpw5rVcSAACAUEpGBgAACGUEOgAAwFoEOgAAwFphG+joU5FTUlIkLS0t2EUBAACtJGwDHZ6MDACA/cI20AEAAPYj0AEAANYi0AEAANYi0AEAANYi0AEAANYi0AEAANYi0AEAANYi0AEAANYi0AEAANZq94FORUWFnHXWWeZ1DoMGDZL58+cHu0gAACBEREk7FxUVJTNnzpQhQ4bI5s2bJTU1VcaNGyeHHnposIsGAACCrN0HOj179jSDSkhIkLi4ONm+fTuBDgAACH7T1ZIlS2TChAmSmJgoERERUlRU1OCbxpOTk6VTp04yfPhwKSkpaXBZK1askNraWunTp08blBwAAIS6oAc6u3fvlsGDB5tgpiHz5s2TqVOnSk5OjqxcudLMO2bMGKmsrPSaT2txrrnmGnniiSfaqOQAACDUBb3pauzYsWZoTF5enkyZMkUmT55sxvPz82XBggVSUFAgWVlZZlp1dbVcdNFFZvzUU09t8vt0Xh1cduzYEbDfAgAAQkvQa3SaUlNTY5qj0tPT3dMiIyPN+NKlS8244zgyadIkOfvss+VXv/rVAZeZm5srsbGx7oFmLgAA7BXSgc62bdtMzk18fLzXdB3XHlbqww8/NM1bmtujPa90+OyzzxpdZnZ2tlRVVbkH7Z4OAADsFPSmq5YaOXKk1NXV+T1/TEyMGTQnSAcNpAAAgJ1CukZHu4p36NBBtmzZ4jVdx7UreUtkZmbK2rVrZdmyZS0sJQAACFUhHehER0ebBwAWFxe7p2ntjY6PGDEiqGUDAAChL+hNV7t27ZKysjL3eHl5uZSWlkr37t0lKSnJdC3PyMiQoUOHyrBhw8xTkLVLuqsXVnPRdAUAgP0iHO22FESLFy+WUaNG1ZuuwU1hYaH5e/bs2TJjxgyTgKzJxrNmzTIPDgwE7V6uva80Mblr164SSMlZCwK6PDRs4/TxwS4CAKCN+Xv9DnqgE2wEOu0fgQ4AhJ8dfl6/QzpHpzVps5W+8TwtLS3YRQEAAK0kbAMdel0BAGC/sA10AACA/Qh0AACAtcI20CFHBwAA+4VtoEOODgAA9gvbQAcAANiPQAcAAFgrbAMdcnQAALBf2AY65OgAAGC/sA10AACA/Qh0AACAtQh0AACAtcI20CEZGQAA+4VtoEMyMgAA9gvbQAcAANiPQAcAAFiLQAcAAFiLQAcAAFiLQAcAAFgrbAMdupcDAGC/sA106F4OAID9wjbQAQAA9iPQAQAA1iLQAQAA1iLQAQAA1iLQAQAA1iLQAQAA1iLQAQAA1iLQAQAA1grbQIcnIwMAYL+wDXR4MjIAAPYL20AHAADYj0AHAABYi0AHAABYi0AHAABYi0AHAABYi0AHAABYi0AHAABYi0AHAABYi0AHAABYy4pAZ+LEidKtWze55JJLgl0UAAAQQqwIdG699VaZO3dusIsBAABCjBWBzllnnSWHHXZYsIsBAABCTNADnSVLlsiECRMkMTFRIiIipKioqME3jScnJ0unTp1k+PDhUlJSEpSyAgCA9iXogc7u3btl8ODBJphpyLx582Tq1KmSk5MjK1euNPOOGTNGKisr27ysAACgfYkKdgHGjh1rhsbk5eXJlClTZPLkyWY8Pz9fFixYIAUFBZKVlXXQ31ddXW0Glx07djSz5AAAINQFPdBpSk1NjaxYsUKys7Pd0yIjIyU9PV2WLl3arGXm5ubKvffeG8BSItiSsxZIe7Nx+vhgFwEAwkLQm66asm3bNqmtrZX4+Hiv6Tq+efNm97gGPpdeeqm8/vrr0rt37yaDIA2aqqqq3ENFRUWr/gYAABA8IV2j46933nnH73ljYmLMoDlBOmggBQAA7BTSNTpxcXHSoUMH2bJli9d0HU9ISGjRsjMzM2Xt2rWybNmyFpYSAACEqpAOdKKjoyU1NVWKi4vd0+rq6sz4iBEjglo2AAAQ+oLedLVr1y4pKytzj5eXl0tpaal0795dkpKSTNfyjIwMGTp0qAwbNkxmzpxpuqS7emE1F01XAADYL8JxHCeYBVi8eLGMGjWq3nQNbgoLC83fs2fPlhkzZpgE5CFDhsisWbPMgwMDQbuXx8bGmsTkrl27Srj3BkLboNcVALTN9TvogU6wEeggGAh0AKBtrt8hnaPTmrTZKiUlRdLS0oJdFAAA0ErCNtCh1xUAAPYL20AHAADYj0AHAABYK2wDHXJ0AACwX9gGOuToAABgv7ANdAAAgP0IdAAAgLXCNtAhRwcAAPuFbaBDjg4AAPYL20AHAADYj0AHAABYi0AHAABYK2wDHZKRAQCwX9gGOiQjAwBgv7ANdAAAgP0IdAAAgLUIdAAAgLUIdAAAgLUIdAAAgLXCNtChezkAAPYL20CH7uUAANgvbAMdAABgPwIdAABgLQIdAABgLQIdAABgLQIdAABgLQIdAABgLQIdAABgLQIdAABgrSgJ4ycj61BbWxvsoiAMJWctkPZo4/TxwS4CAByUsK3R4cnIAADYL2wDHQAAYD8CHQAAYC0CHQAAYC0CHQAAYC0CHQAAYC0CHQAAYC0CHQAAYC0CHQAAYC0CHQAAYC0rAp3XXntNjj/+eOnXr5889dRTwS4OAAAIEe3+XVf79++XqVOnyqJFiyQ2NlZSU1Nl4sSJ0qNHj2AXDQAABFm7r9EpKSmR/v37S69evaRLly4yduxYeeutt4JdLAAAEAKCHugsWbJEJkyYIImJiRIRESFFRUX15tG3jCcnJ0unTp1k+PDhJrhx+fbbb02Q46J/b9q0qc3KDwAAQlfQA53du3fL4MGDTTDTkHnz5pmmqZycHFm5cqWZd8yYMVJZWdms76uurpYdO3Z4DQAAwE5Bz9HRpiYdGpOXlydTpkyRyZMnm/H8/HxZsGCBFBQUSFZWlqkJ8qzB0b+HDRvW6PJyc3Pl3nvvDfCvAMJDctYCaW82Th8f7CIgRLXH/bk92hjkYzDoNTpNqampkRUrVkh6erp7WmRkpBlfunSpGdegZs2aNSbA2bVrlyxcuNDU+DQmOztbqqqq3ENFRUWb/BYAABCGNTpN2bZtm9TW1kp8fLzXdB3/4osvzN9RUVHy8MMPy6hRo6Surk7uuuuuJntcxcTEmAEAANgvpAMdf11wwQVmOBiaE6SDBlIAAMBOId10FRcXJx06dJAtW7Z4TdfxhISEFi07MzNT1q5dK8uWLWthKQEAQKgK6UAnOjraPACwuLjYPU2bp3R8xIgRQS0bAAAIfUFvutIE4rKyMvd4eXm5lJaWSvfu3SUpKcl0Lc/IyJChQ4eaxOOZM2eaLumuXljNRdMVAAD2C3qgs3z5cpNI7KKBjdLgprCwUC677DLZunWr3HPPPbJ582YZMmSIvPHGG/USlJvTdKWDPkdHXx0BAADsE/RA56yzzhLHcZqc56abbjIDAACANTk6rUmbrVJSUiQtLS3YRQEAAK0kbAMdel0BAGC/sA10AACA/Qh0AACAtcI20CFHBwAA+4VtoEOODgAA9gvbQAcAANgv6M/RCTbXM3z0wYGBVle9J+DLBHBwWuPYhh04R7fvY9C13AM9iy/COdAclnK9AqKmpka++uqrYBcHAAA0Q0VFhfTu3bvRz8M20PF8Sei3334rhx12mERERARkmRpl9unTx6z8rl27BmSZtmJd+Y915T/Wlf9YV/5hPYXeutLwZefOnZKYmCiRkY1n4oR905WunKYiwZbQDcwB4R/Wlf9YV/5jXfmPdeUf1lNorSt/3lVJMjIAALAWgQ4AALAWgU4riImJkZycHPN/NI115T/Wlf9YV/5jXfmH9dR+11XYJyMDAAB7UaMDAACsRaADAACsRaADAACsRaADAACsRaADAACsRaDTCvQdWsnJydKpUycZPny4lJSUSLhZsmSJTJgwwTyaW1+tUVRU5PW5dva75557pGfPnnLIIYdIenq6rF+/3mue7du3y1VXXWWerHn44YfLddddJ7t27RKb5ObmSlpamnkFyZFHHikXXXSRrFu3zmuevXv3SmZmpvTo0UO6dOkiF198sWzZssVrnm+++UbGjx8vnTt3Nsu58847Zf/+/WKTxx9/XAYNGuR+2uqIESNk4cKF7s9ZTw2bPn26OQZ/97vfuaexrn72pz/9yawbz+GEE05wf8568rZp0ya5+uqrzfrQ8/bAgQNl+fLloX9e1+7lCJznn3/eiY6OdgoKCpzPP//cmTJlinP44Yc7W7ZsccLJ66+/7vzxj390XnzxRX18gfPSSy95fT59+nQnNjbWKSoqclatWuVccMEFzlFHHeX89NNP7nnOO+88Z/Dgwc7HH3/svP/++86xxx7rXHHFFY5NxowZ48yZM8dZs2aNU1pa6owbN85JSkpydu3a5Z7n+uuvd/r06eMUFxc7y5cvd0455RTn1FNPdX++f/9+Z8CAAU56errz6aefmnUfFxfnZGdnOzZ55ZVXnAULFjhffvmls27dOucPf/iD07FjR7PuFOupvpKSEic5OdkZNGiQc+utt7qns65+lpOT4/Tv39/57rvv3MPWrVvdn7Oe/s/27dudvn37OpMmTXI++eQTZ8OGDc6bb77plJWVhfx5nUAnwIYNG+ZkZma6x2tra53ExEQnNzfXCVe+gU5dXZ2TkJDgzJgxwz3txx9/dGJiYpznnnvOjK9du9b8u2XLlrnnWbhwoRMREeFs2rTJsVVlZaX53e+99557vejFfP78+e55/vOf/5h5li5dasb15BoZGels3rzZPc/jjz/udO3a1amurnZs1q1bN+epp55iPTVg586dTr9+/Zy3337bOfPMM92BDuvKO9DRi25DWE/efv/73zsjR450GhPK53WargKopqZGVqxYYarrPF8aquNLly4NatlCSXl5uWzevNlrPemL2bSZz7We9P9arTl06FD3PDq/rs9PPvlEbFVVVWX+3717d/N/3Z/27dvnta60aj0pKclrXWkVcnx8vHueMWPGmDcIf/7552Kj2tpaef7552X37t2mCYv1VJ82uWiTiuc6Uawrb9q0ok3sRx99tGlS0aYoxXry9sorr5jz8aWXXmqa6E466SR58skn28V5nUAngLZt22ZOwJ47vdJx3QHwM9e6aGo96f/1YPIUFRVlAgBb12VdXZ3JozjttNNkwIABZpr+1ujoaHNyaGpdNbQuXZ/Z5LPPPjO5Evpo+euvv15eeuklSUlJYT350CBw5cqVJgfMF+vq/+hFuLCwUN544w2TA6YX69NPP1127tzJevKxYcMGs4769esnb775ptxwww1yyy23yDPPPBPy5/WoVlsygIO+A1+zZo188MEHwS5KyDr++OOltLTU1Hz961//koyMDHnvvfeCXayQUlFRIbfeequ8/fbbpkMEGjd27Fj335roroFP37595YUXXjDJtPC+EdOamGnTpplxrdHR81V+fr45DkMZNToBFBcXJx06dKiXla/jCQkJQStXqHGti6bWk/6/srLS63PtyaAZ+zauy5tuuklee+01WbRokfTu3ds9XX+rNon++OOPTa6rhtal6zOb6B32scceK6mpqaa2YvDgwfLII4+wnjxok4seOyeffLK5W9ZBg8FZs2aZv/UOm3XVMK29Oe6446SsrIx9yof2pNLaU08nnniiu6kvlM/rBDoBPgnrCbi4uNgrCtZxzSPAz4466iizU3uuJ23T1jZa13rS/+sJRk/aLu+++65Zn3rXZQvN1dYgR5tg9PfpuvGk+1PHjh291pV2P9eTi+e60iYdzxOI3s1r903fE5NtdH+orq5mPXkYPXq0+Z1a8+Ua9E5c809cf7OuGqbdnL/66itzUWef8qZN6r6Pvvjyyy9NDVjIn9dbLc05jLuXa5Z5YWGhyTD/zW9+Y7qXe2blhwPt8aHdLXXQ3SwvL8/8/fXXX7u7Iep6efnll53Vq1c7F154YYPdEE866STTlfGDDz4wPUhs615+ww03mO6Yixcv9uriumfPHq8urtrl/N133zVdXEeMGGEG3y6u5557rumi/sYbbzhHHHGEdV1cs7KyTG+08vJys8/ouPbWeOutt8znrKfGefa6Uqyrn91+++3m2NN96sMPPzTdxLV7uPZ+VKwn70cVREVFOQ888ICzfv1655///KfTuXNn59lnn3XPE6rndQKdVvDoo4+ag0Ofp6PdzfV5AeFm0aJFJsDxHTIyMtxdEe+++24nPj7eBIajR482z0bx9P3335sDoEuXLqa75uTJk00AZZOG1pEO+mwdFz1J3HjjjaYrtZ5YJk6caIIhTxs3bnTGjh3rHHLIIeZErSfwffv2OTa59tprzXM89LjSi4nuM64gR7Ge/A90WFc/u+yyy5yePXuafapXr15m3PO5MKwnb6+++qoJ7PScfcIJJzhPPPGE1+ehel6P0P+0Xn0RAABA8JCjAwAArEWgAwAArEWgAwAArEWgAwAArEWgAwAArEWgAwAArEWgAwAArEWgAwAArEWgAwAArEWgAwAArEWgAwAAxFb/H1ViVznhGW4ZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_features = 120000\n",
    "tk = Tokenizer(lower = True, filters='', num_words=max_features)\n",
    "full_text = list(train['question_text'].values) + list(val['question_text'].values)\n",
    "tk.fit_on_texts(full_text)\n",
    "\n",
    "train_tokenized = tk.texts_to_sequences(train['question_text'].fillna('missing'))\n",
    "val_tokenized = tk.texts_to_sequences(val['question_text'].fillna('missing'))\n",
    "\n",
    "train['question_text'].apply(lambda x: len(x.split())).plot(kind='hist');\n",
    "plt.yscale('log');\n",
    "plt.title('Distribution of question text length in characters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b3df3e-b0d2-4218-9418-2391d519a50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     2,  1590,     1],\n",
       "       [    0,     0,     0, ...,    54,  1843,     1],\n",
       "       [    0,     0,     0, ...,   471,  5302,     1],\n",
       "       ...,\n",
       "       [    0,     0,     0, ..., 11277,  2923,     1],\n",
       "       [    0,     0,     0, ...,  3411,   433,     1],\n",
       "       [    0,     0,     0, ...,     5, 20274,     1]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 603\n",
    "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
    "X_val = pad_sequences(val_tokenized, maxlen = max_len)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9fd59f4-42dd-4a34-a96c-df48d3b8118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a264ba23-f4d2-4f7c-afa7-a77ce2caffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3685bc7-016a-46d1-926a-54834536345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "embedding_path = \"embeddings/glove.840B.300d/glove.840B.300d.txt\"\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore'))\n",
    "# all_embs = np.stack(embedding_index.values())\n",
    "# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std = -0.005838499, 0.48782197\n",
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ac4532-5563-4581-ac20-58496f849e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"embeddings/paragram_300_sl999/paragram_300_sl999.txt\"\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore') if len(o)>100)\n",
    "# all_embs = np.stack(embedding_index.values())\n",
    "# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std = -0.0053247833, 0.49346462\n",
    "embedding_matrix1 = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix1[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e79b29-4c0e-4c80-afcc-2dc21b56e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.mean([embedding_matrix, embedding_matrix1], axis=0)\n",
    "del embedding_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc11bf7-93ad-4850-b2b0-047bc43938d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krum1\\AppData\\Local\\Temp\\ipykernel_27084\\1979542758.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_train, dtype=torch.long)\n",
      "C:\\Users\\krum1\\AppData\\Local\\Temp\\ipykernel_27084\\1979542758.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_train, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.long)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(X_val, dtype=torch.long)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "val = torch.utils.data.TensorDataset(X_val)\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb02ff1-86cc-423c-843f-830f4110bde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ...,   72,  279,    1],\n",
       "        [   0,    0,    0,  ...,  738, 2364,    1],\n",
       "        [   0,    0,    0,  ...,   56,  162,    1],\n",
       "        ...,\n",
       "        [   0,    0,    0,  ...,    8, 1430,    1],\n",
       "        [   0,    0,    0,  ...,   16,  694,    1],\n",
       "        [   0,    0,    0,  ...,   90,  342,    1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8513d8ce-9cd5-4120-bf19-d8c097870fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        hidden_size = 128\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False  # Замораживаем веса эмбеддингов\n",
    "        \n",
    "        self.embedding_dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size * 4, 16)  # hidden_size * 4 = avg_pool + max_pool\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.bn = nn.BatchNorm1d(16)\n",
    "        self.out = nn.Linear(16, 1)\n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        \n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        \n",
    "        avg_pool = torch.mean(h_lstm, 1)  \n",
    "        max_pool, _ = torch.max(h_lstm, 1) \n",
    "        \n",
    "        conc = torch.cat((avg_pool, max_pool), 1)\n",
    "\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "        conc = self.bn(conc)\n",
    "        out = self.out(conc)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "802f8f5d-6862-49d7-884b-4ff4bba83f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bc92cb3-3df9-4533-a315-418986f18a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:13<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1\n",
      "Train loss: 0.14053418244281266\n",
      "Train Precision: 0.6314 | Train Recall: 0.4745 | Train F1 Score: 0.5418\n",
      "Validation loss: 0.0984\n",
      "Validation Precision: 0.7447 | Validation Recall: 0.5571 | Validation F1 Score: 0.6374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:18<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2\n",
      "Train loss: 0.10908841398681016\n",
      "Train Precision: 0.7096 | Train Recall: 0.5161 | Train F1 Score: 0.5976\n",
      "Validation loss: 0.0911\n",
      "Validation Precision: 0.7184 | Validation Recall: 0.6768 | Validation F1 Score: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:18<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 3\n",
      "Train loss: 0.10365186387190248\n",
      "Train Precision: 0.7216 | Train Recall: 0.5411 | Train F1 Score: 0.6185\n",
      "Validation loss: 0.0860\n",
      "Validation Precision: 0.7538 | Validation Recall: 0.6667 | Validation F1 Score: 0.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:15<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 4\n",
      "Train loss: 0.09900199267091504\n",
      "Train Precision: 0.7265 | Train Recall: 0.5663 | Train F1 Score: 0.6365\n",
      "Validation loss: 0.0804\n",
      "Validation Precision: 0.8061 | Validation Recall: 0.6121 | Validation F1 Score: 0.6959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:18<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 5\n",
      "Train loss: 0.09392330356559189\n",
      "Train Precision: 0.7413 | Train Recall: 0.5933 | Train F1 Score: 0.6591\n",
      "Validation loss: 0.0751\n",
      "Validation Precision: 0.8146 | Validation Recall: 0.6602 | Validation F1 Score: 0.7293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:12<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 6\n",
      "Train loss: 0.08714440161164269\n",
      "Train Precision: 0.7484 | Train Recall: 0.6276 | Train F1 Score: 0.6827\n",
      "Validation loss: 0.0694\n",
      "Validation Precision: 0.7485 | Validation Recall: 0.8125 | Validation F1 Score: 0.7792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:11<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 7\n",
      "Train loss: 0.08186870127312175\n",
      "Train Precision: 0.7626 | Train Recall: 0.6662 | Train F1 Score: 0.7111\n",
      "Validation loss: 0.0634\n",
      "Validation Precision: 0.8434 | Validation Recall: 0.7173 | Validation F1 Score: 0.7752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:17<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 8\n",
      "Train loss: 0.07795902378838897\n",
      "Train Precision: 0.7725 | Train Recall: 0.6849 | Train F1 Score: 0.7260\n",
      "Validation loss: 0.0590\n",
      "Validation Precision: 0.8371 | Validation Recall: 0.7735 | Validation F1 Score: 0.8040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:16<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 9\n",
      "Train loss: 0.07562868941633702\n",
      "Train Precision: 0.7776 | Train Recall: 0.6907 | Train F1 Score: 0.7315\n",
      "Validation loss: 0.0574\n",
      "Validation Precision: 0.7982 | Validation Recall: 0.8580 | Validation F1 Score: 0.8270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4082/4082 [04:16<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 10\n",
      "Train loss: 0.07297235867578951\n",
      "Train Precision: 0.7801 | Train Recall: 0.7005 | Train F1 Score: 0.7381\n",
      "Validation loss: 0.0558\n",
      "Validation Precision: 0.8289 | Validation Recall: 0.8549 | Validation F1 Score: 0.8417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = batch_size\n",
    "from tqdm import tqdm\n",
    "model = NeuralNet().to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters())\n",
    "best_f1 = 0\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    all_train_preds = []\n",
    "    all_train_labels = []\n",
    "\n",
    "    for x_batch, y_batch in tqdm(train_loader):\n",
    "        x_batch, y_batch = x_batch.to(device).long(), y_batch.to(device).unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        probs = torch.sigmoid(y_pred)\n",
    "        pred_labels = (probs > 0.5).float()\n",
    "        all_train_preds.extend(pred_labels.cpu().numpy())\n",
    "        all_train_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    all_train_labels = np.array(all_train_labels).flatten()\n",
    "    all_train_preds = np.array(all_train_preds).flatten()\n",
    "\n",
    "    precision_train = precision_score(all_train_labels, all_train_preds)\n",
    "    recall_train = recall_score(all_train_labels, all_train_preds)\n",
    "    f1_train = f1_score(all_train_labels, all_train_preds)\n",
    "    print(f\"Эпоха {epoch+1}\")\n",
    "    print(f\"Train loss: {train_loss}\")\n",
    "    print(f\"Train Precision: {precision_train:.4f} | Train Recall: {recall_train:.4f} | Train F1 Score: {f1_train:.4f}\")\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in test_loader:\n",
    "            x_val, y_val = x_val.to(device).long(), y_val.to(device).unsqueeze(1)\n",
    "            preds = model(x_val)\n",
    "            loss = loss_fn(preds, y_val)\n",
    "            val_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            probs = torch.sigmoid(preds) \n",
    "            pred_labels = (probs > 0.5).float()\n",
    "            all_preds.extend(pred_labels.cpu().numpy()) \n",
    "            all_labels.extend(y_val.cpu().numpy()) \n",
    "\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "\n",
    "    precision_val = precision_score(all_labels, all_preds)\n",
    "    recall_val = recall_score(all_labels, all_preds)\n",
    "    f1_val = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation Precision: {precision_val:.4f} | Validation Recall: {recall_val:.4f} | Validation F1 Score: {f1_val:.4f}\")\n",
    "    if f1_val > best_f1:\n",
    "        best_f1 = f1_val\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    \n",
    "    val_preds = np.zeros((len(val_loader.dataset)))\n",
    "\n",
    "    for i, (x_batch,) in enumerate(val_loader):\n",
    "        x_batch = x_batch.to(device).long()\n",
    "        y_pred = model(x_batch).detach()\n",
    "    \n",
    "\n",
    "        val_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f524af40-e76b-411a-8e21-d29e5c8e95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['prediction'] = (val_preds > 0.5).astype(int)\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
